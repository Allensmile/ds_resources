# KNN 

## Initial Values
- preferred method for choosing the initial values for k-means clustering is:  K-means ++

## Linkage
Single, complete, average, Ward (review types)

## Curse of Dimensionality
curse of dimensionality is a problem because, as the number of dimensions increases, it's likely that the closest points aren't much closer than average, meaning two points being close doesn't mean much.


## Distance Metrics

Some of the distance metrics used in KNN are: 

## Euclidean distance 
- (L2 distance)

## Manhattan distance 
- (city-block aka L1 distance)

## Jaccard distance 
- (1 - (size of intersection/size of union)
- applies to sets, like bag of words)

## Cosine distance 
- which is the degree between 2 vectors 
- better for text data because euclidean distance is sensitive to document length)

## Strings

### Hamming distance 
- for strings - # of positions where the characters are different for equal length strings

### Levenshtein distance 
- string metric - min number of edits needed to change one string to another) for discrete variables like strings

